[env]
time_limit = 50
time_step = 0.25
val_size = 100
test_size = 500
randomize_attributes = false
discretization = 8
# Add gaussian noise to the observed states
add_gaussian_noise_state = false
gaussian_noise_state_stddev = 0.1
# Add gaussian noise to the actions
add_gaussian_noise_action = false
gaussian_noise_action_stddev = 0.1
adversary_scaling = 0.1
# perturb_humans [bool]
perturb_humans = true


[reward]
success_reward = 10
#reward for reaching goal
collision_penalty = -0.25
# penalty for colliding with humans
discomfort_dist = 0
# distance where robot is too close to human (adopted from CrowdNav)
discomfort_penalty_factor = 0
# penalty for being within discomfort_dist of human (adopted from CrowdNav)
edge_discomfort_dist = 0.3
# if robot is within edge_discomfort_dist of the edge of the accessible space, edge_penalty applied
edge_penalty = -.1
closer_goal = .1
# reward for moving closer to the goal in a step


[sim]
train_val_sim = circle_crossing
test_sim = circle_crossing
square_width = 10
# width of square for 'square_crossing' behaviour (adopted from CrowdNav)
circle_radius = 3
# radius of circle for 'circle_crossing' behaviour (adopted from CrowdNav)
accessible_space = 4
# accessible space robot can navigate through is x \in [-accessible_space, accessible_space], y \in [-accessible_space, accessible_space]
goal_region = 3
# goals can be generated within x \in [-goal_region, goal_region], y \in [-goal_region, goal_region]
randomize_goals = true
# if true, then goals will be randomly generated
update_goals = true
# if true, then a new goal will be generated every time a robot reaches it. else, done when goal is reached
human_num = 1


[humans]
visible = true
policy = orca
radius = 0.3
v_pref = 0.5
sensor = coordinates
chase_robot = false
# if true, then human default goal will be robot's next location. Else, default human behaviour (circle_crossing)


[robot]
visible = true
policy = none
radius = 0.3
v_pref = 1
sensor = coordinates


[train_details]
num_stacked_frames = 2