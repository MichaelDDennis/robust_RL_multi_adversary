{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import ray\n",
    "import sys\n",
    "\n",
    "from visualize.linear_env.robust_adaptive_lqr.python import utils\n",
    "from visualize.linear_env.robust_adaptive_lqr.python import examples\n",
    "from visualize.linear_env.robust_adaptive_lqr.python.optimal import OptimalStrategy\n",
    "from visualize.linear_env.robust_adaptive_lqr.python.nominal import NominalStrategy\n",
    "from visualize.linear_env.robust_adaptive_lqr.python.ofu import OFUStrategy\n",
    "from visualize.linear_env.robust_adaptive_lqr.python.sls import SLS_FIRStrategy, SLS_CommonLyapunovStrategy, sls_common_lyapunov, SLSInfeasibleException\n",
    "from visualize.linear_env.robust_adaptive_lqr.python.ts import TSStrategy\n",
    "from visualize.linear_env.robust_adaptive_lqr.python.rl_agent import RLStrategy\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-15 23:53:32,377\tWARNING worker.py:673 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2020-04-15 23:53:32,377\tERROR worker.py:679 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "rng = np.random\n",
    "horizon = 100\n",
    "trials_per_method = 20\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining True System Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_example(A_star, B_star, qr_ratio, prime_horizon, prime_excitation, sigma_excitation=0.1):\n",
    "    n,p = B_star.shape\n",
    "    # design a stabilizing controller\n",
    "    _, K_init = utils.dlqr(A_star, B_star, 1e-3*np.eye(n), np.eye(p))\n",
    "    assert utils.spectral_radius(A_star + B_star.dot(K_init)) < 1\n",
    "    Q = qr_ratio * np.eye(n)\n",
    "    R = np.eye(p)\n",
    "    sigma_w = 1\n",
    "    return A_star, B_star, K_init, Q, R, prime_horizon, prime_excitation, sigma_excitation, sigma_w\n",
    "\n",
    "def laplacian_dynamics(qr_ratio=1e1, prime_horizon=100, prime_excitation=1):\n",
    "    A_star, B_star = examples.unstable_laplacian_dynamics()\n",
    "    return set_up_example(A_star, B_star, qr_ratio, prime_horizon, prime_excitation)\n",
    "\n",
    "def unstable_dynamics(qr_ratio=1e1, prime_horizon=250, prime_excitation=2):\n",
    "    A_star, B_star = examples.transient_dynamics(diag_coeff=2, upperdiag=4)\n",
    "    return set_up_example(A_star, B_star, qr_ratio, prime_horizon, prime_excitation, sigma_excitation=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.01 -0.01 -0.  ]\n",
      " [-0.01 -1.01 -0.01]\n",
      " [-0.   -0.01 -1.01]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[0.04373095 0.01250864 0.00126936]\n",
      " [0.01250864 0.04500031 0.01250864]\n",
      " [0.00126936 0.01250864 0.04373095]]\n",
      "prime_horizon 100\n",
      "prime_excitation 1\n",
      "sigma_excitation 0.1\n",
      "[-0.96145194 -0.96753841 -0.96854745]\n"
     ]
    }
   ],
   "source": [
    "example = laplacian_dynamics() # unstable_dynamics()\n",
    "A_star, B_star, K_init, Q, R, prime_horizon, prime_excitation, sigma_excitation, sigma_w = example\n",
    "\n",
    "print(A_star)\n",
    "print(B_star)\n",
    "print(K_init)\n",
    "print(\"prime_horizon\", prime_horizon)\n",
    "print(\"prime_excitation\", prime_excitation)\n",
    "print(\"sigma_excitation\", sigma_excitation)\n",
    "print(np.linalg.eigvals(A_star + B_star @ K_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructors for different adaptive methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_ctor():\n",
    "    return OptimalStrategy(Q=Q, R=R, A_star=A_star, B_star=B_star, sigma_w=sigma_w)\n",
    "\n",
    "def nominal_ctor():\n",
    "    return NominalStrategy(Q=Q,\n",
    "                          R=R,\n",
    "                          A_star=A_star,\n",
    "                          B_star=B_star,\n",
    "                          sigma_w=sigma_w,\n",
    "                          sigma_explore=sigma_excitation,\n",
    "                          reg=1e-5,\n",
    "                          epoch_multiplier=10, rls_lam=None)\n",
    "\n",
    "def rl_ctor():\n",
    "    import ipdb; ipdb.set_trace()\n",
    "    return RLStrategy(Q=Q,\n",
    "                      R=R,\n",
    "                      A_star=A_star,\n",
    "                      B_star=B_star,\n",
    "                      sigma_w=sigma_w,\n",
    "                      sigma_explore=sigma_excitation,\n",
    "                      reg=1e-5,\n",
    "                      epoch_multiplier=10, rls_lam=None)\n",
    "\n",
    "def ofu_ctor():\n",
    "    return OFUStrategy(Q=Q,\n",
    "                  R=R,\n",
    "                  A_star=A_star,\n",
    "                  B_star=B_star,\n",
    "                  sigma_w=sigma_w,\n",
    "                  reg=1e-5,\n",
    "                  actual_error_multiplier=1, rls_lam=None)\n",
    "\n",
    "def ts_ctor():\n",
    "    return TSStrategy(Q=Q,\n",
    "                  R=R,\n",
    "                  A_star=A_star,\n",
    "                  B_star=B_star,\n",
    "                  sigma_w=sigma_w,\n",
    "                  reg=1e-5,\n",
    "                  tau=500,\n",
    "                  actual_error_multiplier=1, rls_lam=None)\n",
    "\n",
    "def sls_fir_ctor():\n",
    "    return SLS_FIRStrategy(Q=Q,\n",
    "                  R=R,\n",
    "                  A_star=A_star,\n",
    "                  B_star=B_star,\n",
    "                  sigma_w=sigma_w,\n",
    "                  sigma_explore=sigma_excitation,\n",
    "                  reg=1e-5,\n",
    "                  epoch_multiplier=10,\n",
    "                  truncation_length=12,\n",
    "                  actual_error_multiplier=1, rls_lam=None)\n",
    "\n",
    "def sls_cl_ctor():\n",
    "    return SLS_CommonLyapunovStrategy(Q=Q,\n",
    "                  R=R,\n",
    "                  A_star=A_star,\n",
    "                  B_star=B_star,\n",
    "                  sigma_w=sigma_w,\n",
    "                  sigma_explore=sigma_excitation,\n",
    "                  reg=1e-5,\n",
    "                  epoch_multiplier=10,\n",
    "                  actual_error_multiplier=1, rls_lam=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper methods for running in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_seed = 45727\n",
    "def run_one_trial(new_env_ctor, seed, prime_fixed=False):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    if prime_fixed: # reducing variance\n",
    "        rng_prime = np.random.RandomState(prime_seed) \n",
    "    else:\n",
    "        rng_prime = rng\n",
    "    env = new_env_ctor()\n",
    "    env.reset(rng_prime)\n",
    "    env.prime(prime_horizon, K_init, prime_excitation, rng_prime)\n",
    "    regret = np.array([env.step(rng) for _ in range(horizon)])\n",
    "    env.complete_epoch(rng)\n",
    "    err, cost = env.get_statistics(iteration_based=True)\n",
    "    return regret, err, cost\n",
    "\n",
    "def run_one_trial_with_actor(env, seed, prime_fixed=False):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    if prime_fixed: # reducing variance\n",
    "        rng_prime = np.random.RandomState(prime_seed) \n",
    "    else:\n",
    "        rng_prime = rng\n",
    "    env.reset(rng_prime)\n",
    "    env.prime(prime_horizon, K_init, prime_excitation, rng_prime)\n",
    "    regret = np.array([env.step(rng) for _ in range(horizon)])\n",
    "    env.complete_epoch(rng)\n",
    "    err, cost = env.get_statistics(iteration_based=True)\n",
    "    return regret, err, cost\n",
    "\n",
    "def spawn_invocation(method, p, prime_fixed=False):\n",
    "    seed = np.random.randint(0xFFFFFFFF)\n",
    "    ctor = {\n",
    "        'optimal': optimal_ctor,\n",
    "        'nominal': nominal_ctor,\n",
    "        'ofu': ofu_ctor,\n",
    "        'ts': ts_ctor,\n",
    "        'sls_fir': sls_fir_ctor,\n",
    "        'sls_cl': sls_cl_ctor,\n",
    "        \"rl\": rl_ctor\n",
    "    }[method]\n",
    "    return (p.apply_async(run_one_trial, (ctor, seed, prime_fixed)), seed)\n",
    "\n",
    "def process_future_list(ftchs):\n",
    "    regrets = []\n",
    "    errors = []\n",
    "    costs = []\n",
    "    seeds = []\n",
    "    bad_invocations = 0\n",
    "    for ftch, seed in ftchs:\n",
    "        try:\n",
    "            reg, err, cost = ftch.get()\n",
    "        except Exception as e:\n",
    "            bad_invocations += 1\n",
    "            continue\n",
    "        regrets.append(reg)\n",
    "        errors.append(err)\n",
    "        costs.append(cost)\n",
    "        seeds.append(seed)\n",
    "    return np.array(regrets), np.array(errors), np.array(costs), np.array(seeds), bad_invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_one_trial(optimal_ctor, 0, prime_fixed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running experiments and plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 10:54:52,704\tINFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-04-16 10:54:52,733\tINFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward targets are [-10.          -9.52631579  -9.05263158  -8.57894737  -8.10526316\n",
      "  -7.63157895  -7.15789474  -6.68421053  -6.21052632  -5.73684211\n",
      "  -5.26315789  -4.78947368  -4.31578947  -3.84210526  -3.36842105\n",
      "  -2.89473684  -2.42105263  -1.94736842  -1.47368421  -1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-16 10:56:16,392\tWARNING modelv1_compat.py:135 -- It is not recommended to use a LSTM model with vf_share_layers=False (consider setting it to True). If you want to not share layers, you can implement a custom LSTM model that overrides the value_function() method.\n",
      "2020-04-16 10:59:48,704\tINFO trainable.py:102 -- _setup took 295.987 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2020-04-16 10:59:48,705\tWARNING util.py:45 -- Install gputil for GPU system monitoring.\n",
      "2020-04-16 11:00:26,832\tINFO trainable.py:346 -- Restored from checkpoint: /Users/eugenevinitsky/Desktop/Research/Data/sim2real/linear/04-16-2020/linear_DAMLT_20adv_d3_h200_low10_smallbatch/linear_DAMLT_20adv_d3_h200_low10_smallbatch/PPO_4_lambda=0.9,lr=5e-05_2020-04-16_07-36-54xhl7izdk/checkpoint_300/checkpoint-300\n",
      "2020-04-16 11:00:26,833\tINFO trainable.py:353 -- Current state after restoring: {'_iteration': 300, '_timesteps_total': 9000000, '_time_total': 11111.229470729828, '_episodes_total': 45494}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward targets are [-10.          -9.52631579  -9.05263158  -8.57894737  -8.10526316\n",
      "  -7.63157895  -7.15789474  -6.68421053  -6.21052632  -5.73684211\n",
      "  -5.26315789  -4.78947368  -4.31578947  -3.84210526  -3.36842105\n",
      "  -2.89473684  -2.42105263  -1.94736842  -1.47368421  -1.        ]\n"
     ]
    }
   ],
   "source": [
    "actor = rl_ctor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished execution in 14.293593168258667 seconds\n"
     ]
    }
   ],
   "source": [
    "strategies = ['optimal', 'nominal', 'ofu', 'ts']#, 'sls_cl', 'sls_fir']\n",
    "start_time = time.time()\n",
    "with Pool(processes=cpu_count()) as p:\n",
    "    all_futures = [[spawn_invocation(method, p, prime_fixed=True) \n",
    "                    for _ in range(trials_per_method)] for method in strategies]\n",
    "    list_of_results = [process_future_list(ftchs) for ftchs in all_futures]\n",
    "print(\"finished execution in {} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_list = []\n",
    "err_list = []\n",
    "cost_list = []\n",
    "for i in range(trials_per_method):\n",
    "    regret, err, cost = run_one_trial_with_actor(actor, i, prime_fixed=False)\n",
    "    regret_list.append(regret)\n",
    "    err_list.append(err)\n",
    "    cost_list.append(cost)\n",
    "\n",
    "list_of_results.append([regret_list, err_list, cost_list, list_of_results[0][3], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errorbars(regrets, q=10, percent_bad=0):\n",
    "    median = np.percentile(regrets, q=50-percent_bad, axis=0)\n",
    "    low10 = np.percentile(regrets, q=q, axis=0)\n",
    "    high90 = np.percentile(regrets, q=100-(q-percent_bad), axis=0)\n",
    "    return median, low10, high90\n",
    "\n",
    "def plot_list_medquantile(datalist, legendlist=None, xlabel=None, ylabel=None, semilogy=False, \n",
    "                          loc='upper left', alpha=0.1, figsize=(8,4)):\n",
    "    rgblist = sns.color_palette('viridis', len(datalist))\n",
    "    plt.figure(figsize=figsize)\n",
    "    for idx, data in enumerate(datalist):\n",
    "        median, lower, higher = data\n",
    "        if semilogy:\n",
    "            plt.semilogy(range(len(median)), median, color=rgblist[idx], label=legendlist[idx])\n",
    "        else:\n",
    "            plt.plot(range(len(median)), median, color=rgblist[idx], label=legendlist[idx])\n",
    "        plt.fill_between(np.array(np.arange(len(median))), median.astype(np.float), \n",
    "                        higher.astype(np.float), color=rgblist[idx], alpha=alpha)\n",
    "    if legendlist is not None:\n",
    "        plt.legend(loc=loc)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl bad_invocations 0\n",
      "ofu bad_invocations 0\n",
      "ts bad_invocations 0\n",
      "nominal bad_invocations 0\n",
      "optimal bad_invocations 0\n"
     ]
    }
   ],
   "source": [
    "regretlist = []\n",
    "costs_list = []\n",
    "\n",
    "# strat_rearranged =  [strategies[2], strategies[3], strategies[5], strategies[1], strategies[0]]\n",
    "# res_rearranged =  [list_of_results[2], list_of_results[3], list_of_results[5], list_of_results[1], list_of_results[0]]\n",
    "\n",
    "strat_rearranged =  ['rl', strategies[2], strategies[3], strategies[1], strategies[0]]\n",
    "res_rearranged =  [list_of_results[4], list_of_results[2], list_of_results[3], list_of_results[1], list_of_results[0]]\n",
    "\n",
    "for name, result in zip(strat_rearranged, res_rearranged):\n",
    "    regrets, errors, costs, _, bad_invocations = result\n",
    "    print(name, \"bad_invocations\", bad_invocations)\n",
    "    percent_bad = bad_invocations / trials_per_method * 100\n",
    "    regretlist.append(get_errorbars(regrets, q=10, percent_bad=percent_bad))\n",
    "    costs_list.append(get_errorbars(costs, q=10, percent_bad=percent_bad))\n",
    "\n",
    "sns.set_palette(\"muted\")\n",
    "plot_list_medquantile(regretlist, legendlist=strat_rearranged, xlabel=\"Iteration\", ylabel=\"Regret\")\n",
    "plot_list_medquantile(costs_list[:-1], legendlist=strat_rearranged[:-1], xlabel=\"Iteration\", \n",
    "                      ylabel=\"Cost Suboptimality\", semilogy=True, loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "sim2real",
   "language": "python",
   "name": "sim2real"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
